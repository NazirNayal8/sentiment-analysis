{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountHashtags(data):\n",
    "    \"\"\"\n",
    "    count words that start with # given a data string\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "        \n",
    "    count = len([s for s in data.split() if s.startswith('#')])\n",
    "    return count\n",
    "    \n",
    "\n",
    "def CountMentions(data):\n",
    "    \"\"\"\n",
    "    count words that start with @ given a data string\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    count = len([s for s in data.split() if s.startswith('@')])\n",
    "    return count\n",
    "\n",
    "def RemoveHashtags(data):\n",
    "    \"\"\"\n",
    "    Removes hashtags from a given string\n",
    "    \n",
    "    Assuming re library is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    hashtag_regex = '#[A-Za-z0-9]+'\n",
    "    \n",
    "    data = ' '.join(re.sub(hashtag_regex, ' ', data).split())\n",
    "    \n",
    "    return data\n",
    "    \n",
    "\n",
    "def RemoveMentions(data):\n",
    "    \"\"\"\n",
    "    Removes mentions from a given string\n",
    "    \n",
    "    Assuming re library is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    mention_regex = '@[A-Za-z0-9]+'\n",
    "    \n",
    "    data = ' '.join(re.sub(mention_regex, ' ', data).split())\n",
    "    \n",
    "    return data\n",
    "    \n",
    "\n",
    "def CountStopWords(data, stop_words):\n",
    "    \"\"\"\n",
    "    Given a text and a list of stop words, return count of step words in text\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    assert isinstance(stop_words, set)\n",
    "    \n",
    "    count = len([s for s in data.split() if s in stop_words])\n",
    "    return count\n",
    "\n",
    "def RemoveStopWords(data, stop_words):\n",
    "    \"\"\"\n",
    "    Given a test and a list of stop words, remove stop words from text\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    assert isinstance(stop_words, set)\n",
    "    \n",
    "    data = ' '.join([s for s in data.split() if s not in stop_words])\n",
    "    return data\n",
    "\n",
    "def GetWordCount(data):\n",
    "    \"\"\"\n",
    "    count number of words in a given text\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    count = len([s for s in data.split()])\n",
    "    return count\n",
    "\n",
    "def GetCharCount(data):\n",
    "    \"\"\"\n",
    "    count number of characters in a given text\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    return len(data)\n",
    "\n",
    "def GetAvgWordLength(data):\n",
    "    \"\"\"\n",
    "    Given a text, return average word length\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    words = data.split()\n",
    "    \n",
    "    Len = 0\n",
    "    for w in words:\n",
    "        Len += len(w)\n",
    "    \n",
    "    Ans = int(Len / len(words))\n",
    "    return Ans\n",
    "\n",
    "def GetNumericDigitsCount(data):\n",
    "    \"\"\"\n",
    "    Given a text, count number of numerical digits (not imbedded)\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    count = len([s for s in data.split() if s.isdigit()])\n",
    "    return count\n",
    "\n",
    "def CountContractions(data, contractions):\n",
    "    \"\"\"\n",
    "    Given a text and map of contractions, return count of contractions in text\n",
    "    \n",
    "    Make sure all characters are lowercase\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    assert isinstance(contractions, dict)\n",
    "    \n",
    "    count = len([s for s in data.split() if s in contractions])\n",
    "    return count\n",
    "\n",
    "def ExpandContractions(data, contractions):\n",
    "    \"\"\"\n",
    "    Given a text, and a map of contractions, replace contraction in the given text\n",
    "    \n",
    "    Make sure all character are lowercase\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    assert isinstance(contractions, dict)\n",
    "    \n",
    "    for key in contractions:\n",
    "        value = contractions[key]\n",
    "        data = data.replace(key, value)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def GetEmailCount(data):\n",
    "    \"\"\"\n",
    "    Given a text, count number of emails \n",
    "    \n",
    "    Assuming re library is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    email_regex = '([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)'\n",
    "    \n",
    "    count = len(re.findall(email_regex, data))\n",
    "    return count\n",
    "\n",
    "def RemoveEmails(data):\n",
    "    \"\"\"\n",
    "    Given a text, remove all emails from it\n",
    "    \n",
    "    Assuming re library is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    email_regex = email_regex = '([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)'\n",
    "        \n",
    "    data = re.sub(email_regex, '', data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def ExtractEmails(data):\n",
    "    \"\"\"\n",
    "    Given a text, return all emails in this text\n",
    "    \n",
    "    Assuming re library is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    email_regex = '([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)'\n",
    "    \n",
    "    emails = re.findall(email_regex, data)\n",
    "    \n",
    "    return emails\n",
    "\n",
    "def GetUrlCount(data):\n",
    "    \"\"\"\n",
    "    Given a text, count Urls it contains\n",
    "    \n",
    "    Assuming re library is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    url_regex = '(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?'\n",
    "    \n",
    "    count = len(re.findall(url_regex, data))\n",
    "    \n",
    "    return count\n",
    "\n",
    "def RemoveUrls(data):\n",
    "    \"\"\"\n",
    "    Given a text, remove Urls it contains\n",
    "    \n",
    "    Assuming re library is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    url_regex = '(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?'\n",
    "    \n",
    "    data = re.sub(url_regex, '', data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def ExtractUrls(data):\n",
    "    \"\"\"\n",
    "    Given a text, return all Urls it contains\n",
    "    \n",
    "    Assuming re library is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    url_regex = '(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?'\n",
    "    \n",
    "    urls = re.findall(url_regex, data)\n",
    "    \n",
    "    return urls\n",
    "\n",
    "def RemoveSpecialChars(data):\n",
    "    \"\"\"\n",
    "    Given a text, remove special (non-alphanumeric) characters\n",
    "    \n",
    "    Assuming re library is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    special_regex = '[^A-Z a-z 0-9-]+'\n",
    "    \n",
    "    data = re.sub(special_regex, '', data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def RemoveMultipleSpaces(data):\n",
    "    \"\"\"\n",
    "    Given a text, remove multiple whistepaces\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    data = ' '.join(data.split())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def RemoveHTMLTags(data):\n",
    "    \"\"\"\n",
    "    Given a text remove any existing html tags\n",
    "    \n",
    "    Assuming BeautifulSoup is imported from bs4\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    data = BeautifulSoup(data, 'lxml').getText()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def RemoveAccentedChars(data):\n",
    "    \"\"\"\n",
    "    Given a text, remove accented chars\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    data = unicodedata.normalize('NFKD', data).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return data\n",
    "\n",
    "def CorrectSpelling(data):\n",
    "    \"\"\"\n",
    "    Given a text, correct spelling of words using textblob\n",
    "    \n",
    "    Assuming TextBlob is imported from textblob\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    data = TextBlob(data).correct()\n",
    "    return data\n",
    "    \n",
    "\n",
    "def RemovePunctuations(data):\n",
    "    \"\"\"\n",
    "    Given a text, remove its punctuation\n",
    "    \n",
    "    Assuming re is imported\n",
    "    \"\"\"\n",
    "    assert isinstance(data, str)\n",
    "    \n",
    "    punc_regex = '[\\.\\,\\!\\?\\:\\;\\-\\=]'\n",
    "    \n",
    "    data = re.sub(punc_regex, '', data)\n",
    "    return data\n",
    "\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"btw\": \"by the way\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"gonna\": \"going to\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how does\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\" u \": \" you \",\n",
    "\" ur \": \" your \",\n",
    "\" n \": \" and \"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountSentiments(sentiments):\n",
    "    cnt0 = 0\n",
    "    cnt1 = 0\n",
    "    for sent in sentiments:\n",
    "        if sent == 1:\n",
    "            cnt1 += 1\n",
    "        else:\n",
    "            cnt0 += 1\n",
    "            \n",
    "    print(cnt0,cnt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>IDs</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mybirch</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>coZZ</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>Mon Apr 06 22:20:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>2Hood4Hollywood</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>Mon Apr 06 22:20:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mimismo</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment         IDs                          date      flag  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "5          0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "6          0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "7          0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "8          0  1467811795  Mon Apr 06 22:20:05 PDT 2009  NO_QUERY   \n",
       "9          0  1467812025  Mon Apr 06 22:20:09 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "5         joy_wolf                      @Kwesidei not the whole crew   \n",
       "6          mybirch                                        Need a hug   \n",
       "7             coZZ  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
       "8  2Hood4Hollywood               @Tatiana_K nope they didn't have it   \n",
       "9          mimismo                          @twittera que me muera ?   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Columns = ['sentiment', 'IDs', 'date', 'flag', 'user', 'text']\n",
    "RawData = pd.read_csv('twitter_data.csv', encoding = 'ISO-8859-1', names = Columns)\n",
    "RawData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "RawData = RawData.drop(columns = ['IDs','date','flag','user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "N = 15000\n",
    "K = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Soon, it'll be my turn!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>one week ago the weather was freaking hot now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>is nto of housewife material - self-cooked ric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my vacation is slowly drawing to a close  gnite!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>listening to some blake shelton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          4                      Soon, it'll be my turn!!!!   \n",
       "1          0  one week ago the weather was freaking hot now ...\n",
       "2          0  is nto of housewife material - self-cooked ric...\n",
       "3          0   my vacation is slowly drawing to a close  gnite!\n",
       "4          4                   listening to some blake shelton "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle data\n",
    "RawData = RawData.sample(frac = 1).reset_index(drop = True)\n",
    "RawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a subset of the data points\n",
    "Data = RawData.iloc[0:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Soon, it'll be my turn!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>one week ago the weather was freaking hot now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>is nto of housewife material - self-cooked ric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my vacation is slowly drawing to a close  gnite!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>listening to some blake shelton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1                      Soon, it'll be my turn!!!!   \n",
       "1          0  one week ago the weather was freaking hot now ...\n",
       "2          0  is nto of housewife material - self-cooked ric...\n",
       "3          0   my vacation is slowly drawing to a close  gnite!\n",
       "4          1                   listening to some blake shelton "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize sentiment\n",
    "Data.sentiment = Data.sentiment.apply(lambda x : (1 if x == 4 else 0))\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nazirnayal/.local/lib/python3.7/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# turn to lowercase\n",
    "Data.text = Data.text.apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullText = ' '.join([s for s in Data.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hashtags: 429\n",
      "Number of Mentions: 7432\n",
      "Number of Stop Words: 84542\n",
      "Number of Emails: 9\n",
      "Number of Urls: 684\n",
      "Number of Words: 198279\n",
      "Number of chars: 1132289\n",
      "Stop word percentage: 42.637899121944336\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "print(f\"Number of Hashtags: {CountHashtags(FullText)}\")\n",
    "print(f\"Number of Mentions: {CountMentions(FullText)}\")\n",
    "print(f\"Number of Stop Words: {CountStopWords(FullText,STOP_WORDS)}\")\n",
    "print(f\"Number of Emails: {GetEmailCount(FullText)}\")\n",
    "print(f\"Number of Urls: {GetUrlCount(FullText)}\")\n",
    "print(f\"Number of Words: {GetWordCount(FullText)}\")\n",
    "print(f\"Number of chars: {GetCharCount(FullText)}\")\n",
    "print(f\"Stop word percentage: {(CountStopWords(FullText,STOP_WORDS) / GetWordCount(FullText) * 100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Length: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Word Length: {GetAvgWordLength(FullText)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words for nltk:76482\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words_nltk = set(stopwords.words('english'))\n",
    "print(f\"Stop Words for nltk:{CountStopWords(FullText,stop_words_nltk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.text = Data.text.apply(lambda x : RemoveHashtags(x))\n",
    "Data.text = Data.text.apply(lambda x : RemoveMentions(x))\n",
    "Data.text = Data.text.apply(lambda x : ExpandContractions(x, contractions))\n",
    "Data.text = Data.text.apply(lambda x : RemoveStopWords(x, stop_words_nltk))\n",
    "Data.text = Data.text.apply(lambda x : RemoveEmails(x))\n",
    "Data.text = Data.text.apply(lambda x : RemoveUrls(x))\n",
    "Data.text = Data.text.apply(lambda x : RemoveSpecialChars(x))\n",
    "Data.text = Data.text.apply(lambda x : RemoveMultipleSpaces(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>0</td>\n",
       "      <td>mm guess reruns neds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>1</td>\n",
       "      <td>ok enough kinda like one piece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>1</td>\n",
       "      <td>btw ordered yer merch yesterday lt33333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>0</td>\n",
       "      <td>soaked kinds psr next last supper wish peeps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>1</td>\n",
       "      <td>happy birthday good one x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>1</td>\n",
       "      <td>yay trouble partition table root hd04 oo grub ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>1</td>\n",
       "      <td>hahaha dude thanks classmates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>1</td>\n",
       "      <td>hey stephen hope day starts good life london t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0</td>\n",
       "      <td>wishing mail worked public holidays want creme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0</td>\n",
       "      <td>back work much tweet action happening little</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                               text\n",
       "14990          0                               mm guess reruns neds\n",
       "14991          1                     ok enough kinda like one piece\n",
       "14992          1      btw ordered yer merch yesterday lt33333333333\n",
       "14993          0       soaked kinds psr next last supper wish peeps\n",
       "14994          1                          happy birthday good one x\n",
       "14995          1  yay trouble partition table root hd04 oo grub ...\n",
       "14996          1                      hahaha dude thanks classmates\n",
       "14997          1  hey stephen hope day starts good life london t...\n",
       "14998          0     wishing mail worked public holidays want creme\n",
       "14999          0       back work much tweet action happening little"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorize(x):\n",
    "    x = x.lower()\n",
    "    document = nlp(x)\n",
    "    VecSum = np.zeros(shape = (1,K))\n",
    "    count = 0\n",
    "    for word in document:\n",
    "        if word.has_vector:\n",
    "            VecSum += word.vector.T\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        return VecSum\n",
    "    return (VecSum / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300)\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.19310001  0.34520999 -0.45565    ... -0.19885001  0.36790001\n",
      "   0.063049  ]\n",
      " [-0.176725    0.111562   -0.73039499 ...  0.42224999 -0.32248\n",
      "   0.25193001]\n",
      " ...\n",
      " [-0.13937639  0.15059116 -0.23754367 ... -0.12423891 -0.06015768\n",
      "   0.13844042]\n",
      " [ 0.0019617   0.06924688 -0.1928409  ... -0.0473509  -0.0139908\n",
      "   0.033334  ]\n",
      " [-0.06294     0.10436857 -0.241356   ... -0.03703    -0.25994115\n",
      "   0.14882357]]\n"
     ]
    }
   ],
   "source": [
    "DataMatrix = np.zeros(shape = (1,300))\n",
    "print(DataMatrix.shape)\n",
    "for text in Data.text:\n",
    "    DataMatrix = np.append(DataMatrix, Vectorize(text), axis = 0)\n",
    "DataMatrix = DataMatrix[1:]\n",
    "print(DataMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 0 0]\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# store labels in numpy array\n",
    "Labels = Data['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DataTrain, DataTest, LabelTrain, LabelTest = train_test_split(DataMatrix, Labels, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM_Model = SVC(kernel = 'linear')\n",
    "SVM_Model.fit(DataTrain, LabelTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7175\n"
     ]
    }
   ],
   "source": [
    "print(SVM_Model.score(DataTest,LabelTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Dataa\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "H1 = 100\n",
    "H2 = 100\n",
    "OP = 1\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(K, H1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(H1, H2)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(H2, OP)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout = self.dout(h1)\n",
    "        a2 = self.fc2(dout)\n",
    "        h2 = self.prelu(a2)\n",
    "        a4 = self.out(h2)\n",
    "        y = self.out_act(a4)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attack(X,Y):\n",
    "    Net = NeuralNet()\n",
    "    Loss_Func = nn.BCELoss()\n",
    "    Optimizer = torch.optim.Adam(Net.parameters(), lr = LR, betas = (0.9, 0.999))\n",
    "    Torch_Dataset = Dataa.TensorDataset(X,Y)\n",
    "    Loader = Data.DataLoader(\n",
    "        dataset = Torch_Dataset,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        shuffle = True,\n",
    "        num_workers = 4,\n",
    "    )\n",
    "    for Epoch in range(EPOCH):\n",
    "        cnt = 0\n",
    "        s = 0\n",
    "        for step, (Batch_X,Batch_Y) in enumerate(Loader):\n",
    "            Optimizer.zero_grad()\n",
    "            B_X = Variable(Batch_X)\n",
    "            B_Y = Variable(Batch_Y)\n",
    "            Prediction = Net(B_X)\n",
    "            Loss = Loss_Func(Prediction.squeeze(),B_Y)\n",
    "            s = s + Loss.data.item()\n",
    "            cnt = cnt + 1\n",
    "            Loss.backward()\n",
    "            Optimizer.step()\n",
    "        print(s / cnt)\n",
    "    return Net\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5816229686737061\n",
      "0.5470538122653961\n",
      "0.5285517902374267\n",
      "0.511201008796692\n",
      "0.49729148972034454\n",
      "0.4766127440929413\n",
      "0.4655837606191635\n",
      "0.4473522789478302\n",
      "0.43249841618537904\n",
      "0.4193402009606361\n",
      "0.40913747137784956\n",
      "0.40283613264560697\n",
      "0.38524505132436754\n",
      "0.3680121288895607\n",
      "0.3556741573214531\n",
      "0.3516878408789635\n",
      "0.33276761388778686\n",
      "0.33368173804879186\n",
      "0.32297516959905626\n",
      "0.3202146923840046\n",
      "0.30347828069329263\n",
      "0.3034522671997547\n",
      "0.2932321230173111\n",
      "0.29991556027531624\n",
      "0.2863275002539158\n",
      "0.27755482591688635\n",
      "0.2759471394121647\n",
      "0.27127076548337936\n",
      "0.2627236324250698\n",
      "0.2594563396573067\n",
      "0.25281337748467925\n",
      "0.25158387097716334\n",
      "0.2485724566280842\n",
      "0.24026128590106965\n",
      "0.23945632341504097\n",
      "0.2472725460678339\n",
      "0.2535598073303699\n",
      "0.24849701499938964\n",
      "0.2416203423142433\n",
      "0.24107351695001125\n",
      "0.23007780058681965\n",
      "0.23405640935897828\n",
      "0.2174156948029995\n",
      "0.23400286312401294\n",
      "0.21238830187916755\n",
      "0.21839019989967345\n",
      "0.21654404318332673\n",
      "0.2058791289627552\n",
      "0.20451955710351466\n",
      "0.20405176895856858\n",
      "0.2094160246923566\n",
      "0.21744465374946595\n",
      "0.21423611246049404\n",
      "0.20481573294103145\n",
      "0.206721754103899\n",
      "0.21321772057563065\n",
      "0.21361063981056214\n",
      "0.19511532094329595\n",
      "0.1975935217514634\n",
      "0.19531628146767616\n",
      "0.18820263730734588\n",
      "0.18549515533447267\n",
      "0.18211434081196784\n",
      "0.1727311410754919\n",
      "0.18265571434795858\n",
      "0.18760726049542428\n",
      "0.1820506967380643\n",
      "0.20914627477526665\n",
      "0.20474861024320126\n",
      "0.19703154243528842\n",
      "0.1937240468785167\n",
      "0.158397696852684\n",
      "0.17137782247364522\n",
      "0.19423266933858394\n",
      "0.18241971493512393\n",
      "0.18048914311826228\n",
      "0.16956173783540726\n",
      "0.1602460573092103\n",
      "0.17229715107381344\n",
      "0.1696928174123168\n",
      "0.16688599348813296\n",
      "0.1617278534322977\n",
      "0.1701589252948761\n",
      "0.17834596239030362\n",
      "0.18556635469943286\n",
      "0.1707619499787688\n",
      "0.16651627718657255\n",
      "0.17959721299260856\n",
      "0.1829045200869441\n",
      "0.16454378105700015\n",
      "0.16436990801617504\n",
      "0.16025726845115423\n",
      "0.16419396019354462\n",
      "0.1711639014109969\n",
      "0.16440151221305133\n",
      "0.1600819016620517\n",
      "0.1538396044895053\n",
      "0.1734471680149436\n",
      "0.1615248794108629\n",
      "0.15889068000018597\n"
     ]
    }
   ],
   "source": [
    "DataTensor = torch.from_numpy(DataTrain).float()\n",
    "LabelTensor = torch.from_numpy(LabelTrain).float()\n",
    "Network = Attack(DataTensor,LabelTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTestTensor = torch.from_numpy(DataTest).float()\n",
    "LabelTestTensor = torch.from_numpy(LabelTest).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid = Network(DataTestTensor).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "Output = Valid.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mask = [(1 if val > 0.5 else 0) for val in Output]\n",
    "Accuracy = sum(Mask == LabelTest) / len(Mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.689\n"
     ]
    }
   ],
   "source": [
    "print(Accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
